{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26iZvkRjHrSj"
      },
      "source": [
        "# Causal Forest Difference-in-Differences Analysis\n",
        "## Part 1: Data, Methodology, and Core Implementation\n",
        "\n",
        "### Singapore's Prime Location Housing (PLH) Reform Evaluation\n",
        "\n",
        "---\n",
        "\n",
        "**Author:** Naia  Nathan\n",
        "**Affiliation:** Columbia University, Economics  \n",
        "**Advisor:** Professor Jonathan Dingel  \n",
        "\n",
        "---\n",
        "\n",
        "## Abstract\n",
        "\n",
        "This notebook implements the **Causal Forest Difference-in-Differences (CF-DiD)** methodology to evaluate Singapore's Prime Location Housing (PLH) reform, introduced in November 2021. The reform aimed to reduce speculative demand for public housing in prime locations by extending minimum occupancy periods, introducing subsidy clawbacks, and restricting rental options.\n",
        "\n",
        "The analysis follows the methodological framework of:\n",
        "\n",
        "> **Gavrilova, E., Langørgen, A., & Zoutman, F. T. (2025). \"Difference-in-Difference Causal Forests With an Application to Payroll Tax Incidence in Norway.\" *Journal of Applied Econometrics*.**\n",
        "\n",
        "---\n",
        "\n",
        "## Research Design Summary\n",
        "\n",
        "| Element | Specification |\n",
        "|---------|---------------|\n",
        "| **Treatment** | Prime Location Housing (PLH) designation (Nov 2021) |\n",
        "| **Treated Group** | `everprime = 1` (locations ever designated as prime) |\n",
        "| **Control Group** | `everprime = 0` (non-prime locations) |\n",
        "| **Outcome** | `log_prob_first` (log probability of first-timer allocation success) |\n",
        "| **Panel Unit** | Town × Room type combinations |\n",
        "| **Pre-Policy Period** | November 2011 – October 2021 |\n",
        "| **Post-Policy Period** | November 2021 – August 2023 |\n",
        "\n",
        "---\n",
        "\n",
        "## Notebook Structure\n",
        "\n",
        "1. **Setup & Configuration**\n",
        "2. **Data Loading & Preprocessing**\n",
        "3. **Feature Engineering & VIF Analysis**\n",
        "4. **CF-DiD Methodology & Implementation**\n",
        "5. **Core Model Estimation**\n",
        "\n",
        "Results, validation tests, and figures are in **Part 2**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0GjjfBEHrSm"
      },
      "source": [
        "---\n",
        "## 1. Setup & Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mAAWZicHrSm",
        "outputId": "e895ac0e-970a-4b16-c1ef-c56667acc910"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries loaded successfully.\n",
            "NumPy: 2.0.2\n",
            "Pandas: 2.2.2\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "================================================================================\n",
        "SECTION 1: SETUP AND CONFIGURATION\n",
        "================================================================================\n",
        "This section loads all required libraries and configures paths.\n",
        "\n",
        "Requirements:\n",
        "- pandas, numpy, scipy, sklearn, statsmodels, matplotlib, seaborn\n",
        "- Data file: 'btodata_complete.xlsx' in DATA_OUTPUT directory\n",
        "\"\"\"\n",
        "\n",
        "# Core libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Machine learning\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Econometrics\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# Visualization (colorblind-friendly Okabe-Ito palette)\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import seaborn as sns\n",
        "\n",
        "# Paths\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Libraries loaded successfully.\")\n",
        "print(f\"NumPy: {np.__version__}\")\n",
        "print(f\"Pandas: {pd.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lexdEKPTHrSn",
        "outputId": "c06200ce-7bf6-498f-d910-77a6b7cec133"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Environment: colab\n",
            "Data source: /content/drive/MyDrive/thesis/data_output\n",
            "Output directory: /content/drive/MyDrive/thesis/FINAL_OUTPUT\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# PATH CONFIGURATION\n",
        "# =============================================================================\n",
        "# Modify these paths according to your environment\n",
        "\n",
        "# Option 1: Google Colab\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    THESIS_ROOT = Path(\"/content/drive/MyDrive/thesis\")\n",
        "    ENVIRONMENT = \"colab\"\n",
        "except ImportError:\n",
        "    # Option 2: Local environment\n",
        "    THESIS_ROOT = Path(\"./\")  # Adjust to your local path\n",
        "    ENVIRONMENT = \"local\"\n",
        "\n",
        "sys.path.insert(0, str(THESIS_ROOT))\n",
        "\n",
        "# Try importing config, fall back to defaults\n",
        "try:\n",
        "    from config import RAW_DATA, CLEAN_DATA, DATA_OUTPUT\n",
        "except ImportError:\n",
        "    RAW_DATA = THESIS_ROOT / \"rawdata\"\n",
        "    CLEAN_DATA = THESIS_ROOT / \"cleandata\"\n",
        "    DATA_OUTPUT = THESIS_ROOT / \"data_output\"\n",
        "\n",
        "# Output directory\n",
        "OUTPUT = THESIS_ROOT / \"FINAL_OUTPUT\"\n",
        "OUTPUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Environment: {ENVIRONMENT}\")\n",
        "print(f\"Data source: {DATA_OUTPUT}\")\n",
        "print(f\"Output directory: {OUTPUT}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_J8iq_QLHrSo",
        "outputId": "aa3f00be-a050-4098-9819-0f1df9ab54cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visualization styling configured (colorblind-friendly Okabe-Ito palette).\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# VISUALIZATION CONFIGURATION\n",
        "# =============================================================================\n",
        "# Colorblind-friendly palette (Okabe-Ito)\n",
        "# Reference: https://jfly.uni-koeln.de/color/\n",
        "\n",
        "CB_COLORS = {\n",
        "    'blue': '#0072B2',       # Main blue\n",
        "    'orange': '#E69F00',     # Main orange\n",
        "    'green': '#009E73',      # Teal green\n",
        "    'pink': '#CC79A7',       # Reddish purple\n",
        "    'lightblue': '#56B4E9',  # Sky blue\n",
        "    'yellow': '#F0E442',     # Yellow\n",
        "    'vermillion': '#D55E00', # Vermillion (for emphasis)\n",
        "    'black': '#000000',\n",
        "    'gray': '#999999'\n",
        "}\n",
        "\n",
        "# LaTeX-compatible styling\n",
        "plt.rcParams.update({\n",
        "    'font.family': 'serif',\n",
        "    'font.serif': ['Computer Modern Roman', 'Times New Roman', 'DejaVu Serif'],\n",
        "    'text.usetex': False,  # Set True if LaTeX is installed\n",
        "    'font.size': 11,\n",
        "    'axes.labelsize': 12,\n",
        "    'axes.titlesize': 13,\n",
        "    'legend.fontsize': 10,\n",
        "    'xtick.labelsize': 10,\n",
        "    'ytick.labelsize': 10,\n",
        "    'figure.figsize': (10, 6),\n",
        "    'axes.grid': True,\n",
        "    'grid.alpha': 0.3,\n",
        "    'axes.spines.top': False,\n",
        "    'axes.spines.right': False\n",
        "})\n",
        "\n",
        "print(\"Visualization styling configured (colorblind-friendly Okabe-Ito palette).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5mDVaQBHrSo"
      },
      "source": [
        "---\n",
        "## 2. Data Loading & Preprocessing\n",
        "\n",
        "The dataset contains Build-to-Order (BTO) housing allocation outcomes from Singapore's Housing Development Board (HDB), spanning November 2011 to August 2023. Each observation represents a town × room type × allocation cycle combination."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3aMuVK4HrSp",
        "outputId": "5b6affae-3d66-42bf-f475-b575648deda6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "DATA SUMMARY\n",
            "============================================================\n",
            "Total observations: 596\n",
            "Unique panel units (town × room): 73\n",
            "Date range: 2011-11-01 to 2025-10-01\n",
            "Treatment date: 2021-11-01 (period 121)\n",
            "\n",
            "Treatment status distribution:\n",
            "           n_panels  mean_outcome\n",
            "everprime                        \n",
            "0                57     -0.693370\n",
            "1                16     -0.908915\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# DATA LOADING\n",
        "# =============================================================================\n",
        "\n",
        "# Load main dataset\n",
        "df = pd.read_excel(DATA_OUTPUT / 'btodata_complete.xlsx')\n",
        "\n",
        "# Create datetime column\n",
        "df['date'] = pd.to_datetime(df['year_month'])\n",
        "\n",
        "# Create panel identifier: town × room type\n",
        "df['town_room_id'] = df['town'].astype(str) + '_' + df['room'].astype(str)\n",
        "\n",
        "# Create numeric panel ID for fixed effects\n",
        "le = LabelEncoder()\n",
        "df['panel_id'] = le.fit_transform(df['town_room_id'])\n",
        "\n",
        "# Create time period index (months from start)\n",
        "df = df.sort_values('date')\n",
        "df['time_period'] = ((df['date'] - df['date'].min()).dt.days / 30).astype(int)\n",
        "\n",
        "# Treatment date and period\n",
        "TREATMENT_DATE = pd.Timestamp('2021-11-01')\n",
        "TREATMENT_PERIOD = int(((TREATMENT_DATE - df['date'].min()).days / 30))\n",
        "\n",
        "# Sort data\n",
        "df = df.sort_values(['town_room_id', 'date']).reset_index(drop=True)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"DATA SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Total observations: {len(df):,}\")\n",
        "print(f\"Unique panel units (town × room): {df['town_room_id'].nunique()}\")\n",
        "print(f\"Date range: {df['date'].min().strftime('%Y-%m-%d')} to {df['date'].max().strftime('%Y-%m-%d')}\")\n",
        "print(f\"Treatment date: {TREATMENT_DATE.strftime('%Y-%m-%d')} (period {TREATMENT_PERIOD})\")\n",
        "print(\"\\nTreatment status distribution:\")\n",
        "print(df.groupby('everprime').agg({\n",
        "    'town_room_id': 'nunique',\n",
        "    'log_prob_first': 'mean'\n",
        "}).rename(columns={'town_room_id': 'n_panels', 'log_prob_first': 'mean_outcome'}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T15LBpjOHrSq",
        "outputId": "492e9d22-f3f2-483b-d9d2-9c8595fac987"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ANALYSIS PERIOD BREAKDOWN\n",
            "============================================================\n",
            "Pre-policy observations (before Nov 2021): 417\n",
            "Post-policy observations (Nov 2021 - Aug 2023): 76\n",
            "Total analysis observations: 493\n",
            "\n",
            "Observation counts by group and period:\n",
            "                     Pre-Treatment  Post-Treatment\n",
            "Control (Non-Prime)            367              53\n",
            "Treated (Prime)                 50              23\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# DEFINE ANALYSIS PERIOD\n",
        "# =============================================================================\n",
        "\n",
        "# Filter to analysis period (end at Aug 2023 to ensure sufficient post-treatment data)\n",
        "analysis_df = df[df['date'] <= '2023-08-31'].copy()\n",
        "\n",
        "# Create post-treatment indicator\n",
        "analysis_df['post'] = (analysis_df['date'] >= '2021-11-01').astype(int)\n",
        "\n",
        "# Split data\n",
        "pre_policy = analysis_df[analysis_df['post'] == 0]\n",
        "post_policy = analysis_df[analysis_df['post'] == 1]\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ANALYSIS PERIOD BREAKDOWN\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Pre-policy observations (before Nov 2021): {len(pre_policy):,}\")\n",
        "print(f\"Post-policy observations (Nov 2021 - Aug 2023): {len(post_policy):,}\")\n",
        "print(f\"Total analysis observations: {len(analysis_df):,}\")\n",
        "\n",
        "# Treatment-control breakdown\n",
        "breakdown = analysis_df.groupby(['everprime', 'post']).size().unstack(fill_value=0)\n",
        "breakdown.columns = ['Pre-Treatment', 'Post-Treatment']\n",
        "breakdown.index = ['Control (Non-Prime)', 'Treated (Prime)']\n",
        "print(\"\\nObservation counts by group and period:\")\n",
        "print(breakdown)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQPAPSqGHrSq"
      },
      "source": [
        "---\n",
        "## 3. Feature Engineering & VIF Analysis\n",
        "\n",
        "We conduct Variance Inflation Factor (VIF) analysis to identify and remove multicollinear features. This is critical for the random forest's ability to properly attribute importance across correlated features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVwQcVR7HrSq",
        "outputId": "da3f9f5c-f4fd-4855-fdf7-f6a31d5974b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial feature count: 23 continuous features\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# FEATURE DEFINITIONS\n",
        "# =============================================================================\n",
        "\n",
        "# Continuous features for the model\n",
        "CONTINUOUS_FEATURES = [\n",
        "    # Distance features (spatial characteristics)\n",
        "    'dist_park_km', 'dist_supermarket_km', 'dist_hawker_km', 'dist_mrt_km',\n",
        "    'dist_road_km', 'dist_hdb_existing_km', 'dist_hdb_uc_km', 'dist_mbfc_km',\n",
        "    'dist_mall_km', 'dist_elite_km', 'LON',\n",
        "\n",
        "    # Unit characteristics\n",
        "    'room_num', 'wait_time_month',\n",
        "\n",
        "    # Macroeconomic variables\n",
        "    'cpi', 'sti_close', 'sti_volume', 'pc_gni', 'pc_gdp', 'ave_sora_mth',\n",
        "\n",
        "    # Cycle characteristics\n",
        "    'cycle_total_supply', 'cycle_median_dist_mbfc',\n",
        "    'next_cycle_total_supply', 'next_cycle_median_dist_mbfc'\n",
        "]\n",
        "\n",
        "CATEGORICAL_FEATURES = ['town', 'quarter']\n",
        "BINARY_FEATURES = ['mature', 'covid']\n",
        "\n",
        "print(f\"Initial feature count: {len(CONTINUOUS_FEATURES)} continuous features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QCZSmxHiHrSr"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# VIF ANALYSIS FUNCTIONS\n",
        "# =============================================================================\n",
        "\n",
        "def calculate_vif(df, features):\n",
        "    \"\"\"\n",
        "    Calculate Variance Inflation Factor for each feature.\n",
        "\n",
        "    VIF measures multicollinearity:\n",
        "    - VIF = 1: No correlation with other features\n",
        "    - VIF > 5: Moderate multicollinearity (consider removal)\n",
        "    - VIF > 10: High multicollinearity (strong case for removal)\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : DataFrame\n",
        "        Data containing the features\n",
        "    features : list\n",
        "        List of feature column names\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    DataFrame with features and their VIF values, sorted descending\n",
        "    \"\"\"\n",
        "    X = df[features].dropna()\n",
        "    X = StandardScaler().fit_transform(X)\n",
        "    X = pd.DataFrame(X, columns=features)\n",
        "\n",
        "    vif_data = pd.DataFrame()\n",
        "    vif_data['Feature'] = features\n",
        "    vif_data['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "    return vif_data.sort_values('VIF', ascending=False)\n",
        "\n",
        "\n",
        "def iterative_vif_selection(df, features, threshold=5):\n",
        "    \"\"\"\n",
        "    Iteratively remove features with highest VIF until all are below threshold.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : DataFrame\n",
        "        Data containing the features\n",
        "    features : list\n",
        "        Initial list of feature column names\n",
        "    threshold : float\n",
        "        VIF threshold (default 5)\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    tuple: (remaining_features, removed_features, final_vif_df)\n",
        "    \"\"\"\n",
        "    remaining = features.copy()\n",
        "    removed = []\n",
        "\n",
        "    while True:\n",
        "        vif = calculate_vif(df, remaining)\n",
        "        max_vif = vif['VIF'].max()\n",
        "\n",
        "        if max_vif < threshold:\n",
        "            break\n",
        "\n",
        "        # Remove feature with highest VIF\n",
        "        feature_to_remove = vif.iloc[0]['Feature']\n",
        "        remaining.remove(feature_to_remove)\n",
        "        removed.append((feature_to_remove, max_vif))\n",
        "\n",
        "    return remaining, removed, calculate_vif(df, remaining)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xoN6CheHrSr",
        "outputId": "14090d6c-23c7-466b-c4ea-66faf16b904b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "INITIAL VIF ANALYSIS\n",
            "============================================================\n",
            "                    Feature        VIF\n",
            "                     pc_gdp 147.218811\n",
            "                     pc_gni 129.539884\n",
            "                        cpi   9.674119\n",
            "               ave_sora_mth   4.334480\n",
            "               dist_mbfc_km   4.285315\n",
            "               dist_road_km   4.091847\n",
            "              dist_elite_km   3.983463\n",
            "       dist_hdb_existing_km   3.361470\n",
            "                 sti_volume   3.023693\n",
            "        dist_supermarket_km   2.666828\n",
            "                dist_mrt_km   2.278741\n",
            "               dist_park_km   2.144368\n",
            "                        LON   2.123123\n",
            "            wait_time_month   1.997198\n",
            "                  sti_close   1.928975\n",
            "    next_cycle_total_supply   1.807315\n",
            "         cycle_total_supply   1.746267\n",
            "             dist_hawker_km   1.527340\n",
            "next_cycle_median_dist_mbfc   1.413499\n",
            "     cycle_median_dist_mbfc   1.406789\n",
            "             dist_hdb_uc_km   1.405424\n",
            "               dist_mall_km   1.292405\n",
            "                   room_num   1.050599\n",
            "\n",
            "============================================================\n",
            "ITERATIVE VIF SELECTION (threshold=5)\n",
            "============================================================\n",
            "\n",
            "Features removed due to high VIF:\n",
            "  - pc_gdp: VIF = 147.22\n",
            "  - cpi: VIF = 9.67\n",
            "\n",
            "Final selected features (21):\n",
            "                    Feature      VIF\n",
            "               dist_mbfc_km 4.276781\n",
            "               dist_road_km 3.978359\n",
            "              dist_elite_km 3.976028\n",
            "                     pc_gni 3.435848\n",
            "       dist_hdb_existing_km 3.237458\n",
            "               ave_sora_mth 2.905767\n",
            "                 sti_volume 2.434249\n",
            "        dist_supermarket_km 2.424876\n",
            "                dist_mrt_km 2.240317\n",
            "                        LON 2.115825\n",
            "               dist_park_km 2.114621\n",
            "            wait_time_month 1.937294\n",
            "                  sti_close 1.768196\n",
            "         cycle_total_supply 1.528422\n",
            "             dist_hawker_km 1.513788\n",
            "    next_cycle_total_supply 1.503101\n",
            "next_cycle_median_dist_mbfc 1.402989\n",
            "     cycle_median_dist_mbfc 1.400240\n",
            "             dist_hdb_uc_km 1.330991\n",
            "               dist_mall_km 1.287351\n",
            "                   room_num 1.048303\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# RUN VIF ANALYSIS\n",
        "# =============================================================================\n",
        "\n",
        "# Initial VIF analysis\n",
        "print(\"=\"*60)\n",
        "print(\"INITIAL VIF ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "vif_initial = calculate_vif(analysis_df, CONTINUOUS_FEATURES)\n",
        "print(vif_initial.to_string(index=False))\n",
        "\n",
        "# Iterative selection with threshold=5\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ITERATIVE VIF SELECTION (threshold=5)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "final_features, removed_features, final_vif = iterative_vif_selection(\n",
        "    analysis_df, CONTINUOUS_FEATURES, threshold=5\n",
        ")\n",
        "\n",
        "print(\"\\nFeatures removed due to high VIF:\")\n",
        "for feat, vif_val in removed_features:\n",
        "    print(f\"  - {feat}: VIF = {vif_val:.2f}\")\n",
        "\n",
        "print(f\"\\nFinal selected features ({len(final_features)}):\")\n",
        "print(final_vif.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQOFGWILHrSr",
        "outputId": "7db5c069-9d90-4bf1-a38c-d6fecbf353c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "FINAL ANALYSIS DATASET\n",
            "============================================================\n",
            "Features used: 21\n",
            "Observations after cleaning: 493\n",
            "Treated post-reform observations: 23\n",
            "\n",
            "VIF results saved to: /content/drive/MyDrive/thesis/FINAL_OUTPUT/vif_analysis.csv\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# FINALIZE ANALYSIS FEATURES\n",
        "# =============================================================================\n",
        "\n",
        "# Use VIF-selected features\n",
        "ANALYSIS_FEATURES = final_features.copy()\n",
        "\n",
        "# Clean data: drop rows with missing values in analysis features\n",
        "analysis_df_clean = analysis_df.dropna(subset=ANALYSIS_FEATURES + ['log_prob_first']).copy()\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"FINAL ANALYSIS DATASET\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Features used: {len(ANALYSIS_FEATURES)}\")\n",
        "print(f\"Observations after cleaning: {len(analysis_df_clean):,}\")\n",
        "print(f\"Treated post-reform observations: {len(analysis_df_clean[(analysis_df_clean['everprime']==1) & (analysis_df_clean['post']==1)])}\")\n",
        "\n",
        "# Save VIF results\n",
        "vif_results = pd.DataFrame({\n",
        "    'Feature': [f[0] for f in removed_features] + final_features,\n",
        "    'Status': ['Removed']*len(removed_features) + ['Retained']*len(final_features),\n",
        "    'Final_VIF': [f[1] for f in removed_features] + final_vif['VIF'].tolist()\n",
        "})\n",
        "vif_results.to_csv(OUTPUT / 'vif_analysis.csv', index=False)\n",
        "print(f\"\\nVIF results saved to: {OUTPUT / 'vif_analysis.csv'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2JpIdroHrSr"
      },
      "source": [
        "---\n",
        "## 4. CF-DiD Methodology & Implementation\n",
        "\n",
        "### Theoretical Foundation\n",
        "\n",
        "The Causal Forest Difference-in-Differences (CF-DiD) methodology, following **Gavrilova, Langørgen, & Zoutman (2025)**, addresses the challenge of estimating causal effects when:\n",
        "\n",
        "1. **Standard parallel trends fails** due to heterogeneity in pre-treatment trajectories\n",
        "2. **Treatment groups are sparse** (few treated units)\n",
        "3. **High-dimensional covariates** need to be flexibly controlled\n",
        "\n",
        "### Key Assumptions\n",
        "\n",
        "1. **Conditional Parallel Trends**: After conditioning on observables $X$, treated and control groups would have followed parallel paths absent treatment.\n",
        "\n",
        "$$E[Y_{it}(0) - Y_{it-1}(0) | D_i=1, X_i] = E[Y_{it}(0) - Y_{it-1}(0) | D_i=0, X_i]$$\n",
        "\n",
        "2. **No Anticipation**: Treatment effects only begin after the policy implementation date.\n",
        "\n",
        "3. **SUTVA**: No spillovers between treated and control units.\n",
        "\n",
        "### Estimation Procedure\n",
        "\n",
        "**Step 1**: Train a random forest on control group data to learn $\\hat{\\mu}(X, t) = E[Y | X, t, D=0]$\n",
        "\n",
        "**Step 2**: Predict counterfactual outcomes for treated units: $\\hat{Y}_{it}(0) = \\hat{\\mu}(X_i, t)$\n",
        "\n",
        "**Step 3**: Compute individual treatment effects: $\\hat{\\tau}_i = Y_{it} - \\hat{Y}_{it}(0)$\n",
        "\n",
        "**Step 4**: Average Treatment Effect on the Treated (ATT): $\\hat{\\tau}_{ATT} = \\frac{1}{N_T} \\sum_{i: D_i=1, t>\\tau} \\hat{\\tau}_i$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFZUW5VBHrSs",
        "outputId": "3a1dbc1c-5297-471f-b9bd-53d4d47fdc0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CausalForestDiD class defined successfully.\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# CF-DiD ESTIMATOR CLASS\n",
        "# =============================================================================\n",
        "\n",
        "class CausalForestDiD:\n",
        "    \"\"\"\n",
        "    Causal Forest Difference-in-Differences Estimator\n",
        "\n",
        "    Implements the methodology from:\n",
        "    Gavrilova, E., Langørgen, A., & Zoutman, F. T. (2025).\n",
        "    \"Difference-in-Difference Causal Forests With an Application to\n",
        "    Payroll Tax Incidence in Norway.\" Journal of Applied Econometrics.\n",
        "\n",
        "    The estimator:\n",
        "    1. Trains a random forest on control units to predict outcomes\n",
        "    2. Uses the trained model to generate counterfactual predictions for treated units\n",
        "    3. Computes treatment effects as the difference between observed and counterfactual\n",
        "    4. Provides inference via clustered bootstrap\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    n_trees : int\n",
        "        Number of trees in the random forest (default: 500)\n",
        "    max_depth : int or None\n",
        "        Maximum depth of trees (default: None, unlimited)\n",
        "    min_samples_leaf : int\n",
        "        Minimum samples per leaf node (default: 5)\n",
        "    n_bootstrap : int\n",
        "        Number of bootstrap iterations for inference (default: 200)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_trees=500, max_depth=None, min_samples_leaf=5, n_bootstrap=200):\n",
        "        self.n_trees = n_trees\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.n_bootstrap = n_bootstrap\n",
        "        self.outcome_model = None\n",
        "        self.att_estimate = None\n",
        "        self.att_se = None\n",
        "        self.att_ci_lower = None\n",
        "        self.att_ci_upper = None\n",
        "\n",
        "    def _prepare_features(self, df, feature_cols):\n",
        "        \"\"\"Prepare feature matrix.\"\"\"\n",
        "        return df[feature_cols].values\n",
        "\n",
        "    def fit(self, df, outcome_col, treatment_col, post_col, panel_col, time_col, feature_cols):\n",
        "        \"\"\"\n",
        "        Fit the CF-DiD model.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        df : DataFrame\n",
        "            Panel dataset\n",
        "        outcome_col : str\n",
        "            Name of outcome variable\n",
        "        treatment_col : str\n",
        "            Name of treatment indicator (0/1, time-invariant)\n",
        "        post_col : str\n",
        "            Name of post-treatment period indicator\n",
        "        panel_col : str\n",
        "            Name of panel unit identifier\n",
        "        time_col : str\n",
        "            Name of time period variable\n",
        "        feature_cols : list\n",
        "            List of feature column names\n",
        "        \"\"\"\n",
        "        # Store column names\n",
        "        self.outcome_col = outcome_col\n",
        "        self.treatment_col = treatment_col\n",
        "        self.post_col = post_col\n",
        "        self.panel_col = panel_col\n",
        "        self.time_col = time_col\n",
        "        self.feature_cols = feature_cols\n",
        "\n",
        "        # =====================================================================\n",
        "        # STEP 1: Train outcome model on control group (all periods)\n",
        "        # =====================================================================\n",
        "        control_data = df[df[treatment_col] == 0].copy()\n",
        "\n",
        "        X_control = self._prepare_features(control_data, feature_cols)\n",
        "        y_control = control_data[outcome_col].values\n",
        "\n",
        "        # Add time fixed effects via dummies\n",
        "        time_dummies = pd.get_dummies(control_data[time_col], prefix='t')\n",
        "        X_control_full = np.hstack([X_control, time_dummies.values])\n",
        "        self.time_dummy_cols = time_dummies.columns.tolist()\n",
        "\n",
        "        # Train random forest\n",
        "        self.outcome_model = RandomForestRegressor(\n",
        "            n_estimators=self.n_trees,\n",
        "            max_depth=self.max_depth,\n",
        "            min_samples_leaf=self.min_samples_leaf,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        self.outcome_model.fit(X_control_full, y_control)\n",
        "\n",
        "        # =====================================================================\n",
        "        # STEP 2: Predict counterfactual for treated units in post-period\n",
        "        # =====================================================================\n",
        "        treated_post = df[(df[treatment_col] == 1) & (df[post_col] == 1)].copy()\n",
        "\n",
        "        X_treated = self._prepare_features(treated_post, feature_cols)\n",
        "        time_dummies_treated = pd.get_dummies(treated_post[time_col], prefix='t')\n",
        "\n",
        "        # Align time dummies with training set\n",
        "        for col in self.time_dummy_cols:\n",
        "            if col not in time_dummies_treated.columns:\n",
        "                time_dummies_treated[col] = 0\n",
        "        time_dummies_treated = time_dummies_treated[self.time_dummy_cols]\n",
        "\n",
        "        X_treated_full = np.hstack([X_treated, time_dummies_treated.values])\n",
        "\n",
        "        # Generate counterfactual predictions\n",
        "        y_counterfactual = self.outcome_model.predict(X_treated_full)\n",
        "        y_observed = treated_post[outcome_col].values\n",
        "\n",
        "        # =====================================================================\n",
        "        # STEP 3: Compute individual treatment effects\n",
        "        # =====================================================================\n",
        "        self.individual_effects = y_observed - y_counterfactual\n",
        "        self.treated_post_df = treated_post.copy()\n",
        "        self.treated_post_df['tau_hat'] = self.individual_effects\n",
        "        self.treated_post_df['y_counterfactual'] = y_counterfactual\n",
        "\n",
        "        # =====================================================================\n",
        "        # STEP 4: Compute ATT and inference\n",
        "        # =====================================================================\n",
        "        self.att_estimate = np.mean(self.individual_effects)\n",
        "        self._bootstrap_inference(df)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def _bootstrap_inference(self, df):\n",
        "        \"\"\"\n",
        "        Clustered bootstrap for ATT standard error.\n",
        "\n",
        "        Clusters at the panel level to account for within-panel correlation.\n",
        "        \"\"\"\n",
        "        bootstrap_atts = []\n",
        "\n",
        "        for b in range(self.n_bootstrap):\n",
        "            # Resample panels (clustered bootstrap)\n",
        "            panels = df[self.panel_col].unique()\n",
        "            sampled_panels = np.random.choice(panels, size=len(panels), replace=True)\n",
        "\n",
        "            # Create bootstrap sample\n",
        "            boot_dfs = []\n",
        "            for i, p in enumerate(sampled_panels):\n",
        "                panel_df = df[df[self.panel_col] == p].copy()\n",
        "                panel_df['boot_panel'] = i\n",
        "                boot_dfs.append(panel_df)\n",
        "            boot_df = pd.concat(boot_dfs, ignore_index=True)\n",
        "\n",
        "            # Re-estimate on bootstrap sample\n",
        "            control_data = boot_df[boot_df[self.treatment_col] == 0]\n",
        "            X_control = self._prepare_features(control_data, self.feature_cols)\n",
        "            y_control = control_data[self.outcome_col].values\n",
        "\n",
        "            time_dummies = pd.get_dummies(control_data[self.time_col], prefix='t')\n",
        "            for col in self.time_dummy_cols:\n",
        "                if col not in time_dummies.columns:\n",
        "                    time_dummies[col] = 0\n",
        "            time_dummies = time_dummies.reindex(columns=self.time_dummy_cols, fill_value=0)\n",
        "            X_control_full = np.hstack([X_control, time_dummies.values])\n",
        "\n",
        "            # Fit model (fewer trees for speed)\n",
        "            rf = RandomForestRegressor(\n",
        "                n_estimators=100,\n",
        "                max_depth=self.max_depth,\n",
        "                min_samples_leaf=self.min_samples_leaf,\n",
        "                random_state=42 + b,\n",
        "                n_jobs=-1\n",
        "            )\n",
        "            rf.fit(X_control_full, y_control)\n",
        "\n",
        "            # Predict counterfactual\n",
        "            treated_post = boot_df[(boot_df[self.treatment_col] == 1) &\n",
        "                                   (boot_df[self.post_col] == 1)]\n",
        "            if len(treated_post) == 0:\n",
        "                continue\n",
        "\n",
        "            X_treated = self._prepare_features(treated_post, self.feature_cols)\n",
        "            time_dummies_treated = pd.get_dummies(treated_post[self.time_col], prefix='t')\n",
        "            for col in self.time_dummy_cols:\n",
        "                if col not in time_dummies_treated.columns:\n",
        "                    time_dummies_treated[col] = 0\n",
        "            time_dummies_treated = time_dummies_treated.reindex(\n",
        "                columns=self.time_dummy_cols, fill_value=0\n",
        "            )\n",
        "            X_treated_full = np.hstack([X_treated, time_dummies_treated.values])\n",
        "\n",
        "            y_cf = rf.predict(X_treated_full)\n",
        "            y_obs = treated_post[self.outcome_col].values\n",
        "\n",
        "            boot_att = np.mean(y_obs - y_cf)\n",
        "            bootstrap_atts.append(boot_att)\n",
        "\n",
        "        self.bootstrap_atts = np.array(bootstrap_atts)\n",
        "        self.att_se = np.std(bootstrap_atts)\n",
        "        self.att_ci_lower = np.percentile(bootstrap_atts, 2.5)\n",
        "        self.att_ci_upper = np.percentile(bootstrap_atts, 97.5)\n",
        "\n",
        "    def summary(self):\n",
        "        \"\"\"\n",
        "        Print and return summary of estimation results.\n",
        "        \"\"\"\n",
        "        t_stat = self.att_estimate / self.att_se if self.att_se > 0 else np.nan\n",
        "        p_value = 2 * (1 - stats.norm.cdf(abs(t_stat)))\n",
        "\n",
        "        print(\"=\"*60)\n",
        "        print(\"CF-DiD ESTIMATION RESULTS\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"\\nAverage Treatment Effect on the Treated (ATT):\")\n",
        "        print(f\"  Estimate:     {self.att_estimate:.4f}\")\n",
        "        print(f\"  Std. Error:   {self.att_se:.4f}\")\n",
        "        print(f\"  t-statistic:  {t_stat:.4f}\")\n",
        "        print(f\"  p-value:      {p_value:.4f}\")\n",
        "        print(f\"  95% CI:       [{self.att_ci_lower:.4f}, {self.att_ci_upper:.4f}]\")\n",
        "        print(f\"\\nNumber of treated post-treatment obs: {len(self.individual_effects)}\")\n",
        "        print(f\"Bootstrap iterations: {self.n_bootstrap}\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        return {\n",
        "            'ATT': self.att_estimate,\n",
        "            'SE': self.att_se,\n",
        "            't_stat': t_stat,\n",
        "            'p_value': p_value,\n",
        "            'CI_lower': self.att_ci_lower,\n",
        "            'CI_upper': self.att_ci_upper,\n",
        "            'n_treated_post': len(self.individual_effects)\n",
        "        }\n",
        "\n",
        "print(\"CausalForestDiD class defined successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZDbVY9uHrSs"
      },
      "source": [
        "---\n",
        "## 5. Core Model Estimation\n",
        "\n",
        "We now estimate the main CF-DiD model. The key result is the Average Treatment Effect on the Treated (ATT), which measures the impact of PLH reform on first-timer allocation probability for prime locations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFsPulc4HrSt",
        "outputId": "c201644e-d784-4107-9a60-841611c95b79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting CF-DiD model (this may take a few minutes)...\n",
            "\n",
            "============================================================\n",
            "CF-DiD ESTIMATION RESULTS\n",
            "============================================================\n",
            "\n",
            "Average Treatment Effect on the Treated (ATT):\n",
            "  Estimate:     0.4987\n",
            "  Std. Error:   0.2286\n",
            "  t-statistic:  2.1812\n",
            "  p-value:      0.0292\n",
            "  95% CI:       [0.1901, 1.0120]\n",
            "\n",
            "Number of treated post-treatment obs: 23\n",
            "Bootstrap iterations: 200\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# FIT CF-DiD MODEL\n",
        "# =============================================================================\n",
        "\n",
        "print(\"Fitting CF-DiD model (this may take a few minutes)...\\n\")\n",
        "\n",
        "# Initialize and fit model\n",
        "cfdid = CausalForestDiD(\n",
        "    n_trees=500,\n",
        "    min_samples_leaf=5,\n",
        "    n_bootstrap=200\n",
        ")\n",
        "\n",
        "cfdid.fit(\n",
        "    df=analysis_df_clean,\n",
        "    outcome_col='log_prob_first',\n",
        "    treatment_col='everprime',\n",
        "    post_col='post',\n",
        "    panel_col='panel_id',\n",
        "    time_col='time_period',\n",
        "    feature_cols=ANALYSIS_FEATURES\n",
        ")\n",
        "\n",
        "# Print summary\n",
        "att_results = cfdid.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMOveZE_HrSt",
        "outputId": "8e7f9d93-58bb-4dc5-f2e0-96c9f60c5682"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Main results saved to: cfdid_att_results.csv\n",
            "\n",
            "       Statistic  Value\n",
            "    ATT Estimate 0.4987\n",
            "  Standard Error 0.2286\n",
            "     t-statistic 2.1812\n",
            "         p-value 0.0292\n",
            "    95% CI Lower 0.1901\n",
            "    95% CI Upper 1.0120\n",
            "N (treated post)     23\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# SAVE MAIN RESULTS\n",
        "# =============================================================================\n",
        "\n",
        "# Create results table\n",
        "att_table = pd.DataFrame({\n",
        "    'Statistic': ['ATT Estimate', 'Standard Error', 't-statistic', 'p-value',\n",
        "                  '95% CI Lower', '95% CI Upper', 'N (treated post)'],\n",
        "    'Value': [\n",
        "        f\"{att_results['ATT']:.4f}\",\n",
        "        f\"{att_results['SE']:.4f}\",\n",
        "        f\"{att_results['t_stat']:.4f}\",\n",
        "        f\"{att_results['p_value']:.4f}\",\n",
        "        f\"{att_results['CI_lower']:.4f}\",\n",
        "        f\"{att_results['CI_upper']:.4f}\",\n",
        "        str(att_results['n_treated_post'])\n",
        "    ]\n",
        "})\n",
        "\n",
        "att_table.to_csv(OUTPUT / 'cfdid_att_results.csv', index=False)\n",
        "print(\"Main results saved to: cfdid_att_results.csv\")\n",
        "print(\"\\n\" + att_table.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlw6HUiVHrSt",
        "outputId": "c0c7e0dd-2634-414a-b739-d1c0c4a85101"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "INTERPRETATION\n",
            "============================================================\n",
            "\n",
            "The PLH reform is estimated to increase first-timer allocation\n",
            "probability in prime locations by approximately 64.7%\n",
            "(95% CI: 20.9% to 175.1%)\n",
            "\n",
            "Statistical significance: p = 0.0292\n",
            "Result is statistically significant at the 5% level.\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# INTERPRETATION OF RESULTS\n",
        "# =============================================================================\n",
        "\n",
        "# Convert log effect to percentage change\n",
        "pct_change = (np.exp(att_results['ATT']) - 1) * 100\n",
        "pct_lower = (np.exp(att_results['CI_lower']) - 1) * 100\n",
        "pct_upper = (np.exp(att_results['CI_upper']) - 1) * 100\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"INTERPRETATION\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nThe PLH reform is estimated to increase first-timer allocation\")\n",
        "print(f\"probability in prime locations by approximately {pct_change:.1f}%\")\n",
        "print(f\"(95% CI: {pct_lower:.1f}% to {pct_upper:.1f}%)\")\n",
        "print(f\"\\nStatistical significance: p = {att_results['p_value']:.4f}\")\n",
        "if att_results['p_value'] < 0.05:\n",
        "    print(\"Result is statistically significant at the 5% level.\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dI13FTxOHrSt",
        "outputId": "3ecb3206-7710-446c-d2fb-2aa8bca61b89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Objects saved for Part 2 notebook.\n",
            "Output file: /content/drive/MyDrive/thesis/FINAL_OUTPUT/part1_objects.pkl\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# SAVE OBJECTS FOR PART 2\n",
        "# =============================================================================\n",
        "\n",
        "import pickle\n",
        "\n",
        "# Save model and data for Part 2\n",
        "objects_to_save = {\n",
        "    'cfdid': cfdid,\n",
        "    'analysis_df_clean': analysis_df_clean,\n",
        "    'ANALYSIS_FEATURES': ANALYSIS_FEATURES,\n",
        "    'TREATMENT_PERIOD': TREATMENT_PERIOD,\n",
        "    'TREATMENT_DATE': TREATMENT_DATE,\n",
        "    'CB_COLORS': CB_COLORS,\n",
        "    'att_results': att_results\n",
        "}\n",
        "\n",
        "with open(OUTPUT / 'part1_objects.pkl', 'wb') as f:\n",
        "    pickle.dump(objects_to_save, f)\n",
        "\n",
        "print(\"Objects saved for Part 2 notebook.\")\n",
        "print(f\"Output file: {OUTPUT / 'part1_objects.pkl'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKAd7cEdHrSt"
      },
      "source": [
        "---\n",
        "## Summary & Next Steps\n",
        "\n",
        "### Key Results from Part 1\n",
        "\n",
        "1. **Data**: 493 observations spanning Nov 2011 - Aug 2023, with 23 treated post-reform observations\n",
        "2. **Feature Selection**: VIF analysis reduced features from 23 to 21, removing `pc_gdp` and `cpi` due to high multicollinearity\n",
        "3. **Main Estimate**: ATT ≈ 0.50 (SE ≈ 0.23), corresponding to ~50% increase in first-timer allocation probability\n",
        "\n",
        "### Proceed to Part 2\n",
        "\n",
        "Part 2 contains:\n",
        "- Parallel trends tests (naive and conditional)\n",
        "- Event study analysis\n",
        "- Placebo tests\n",
        "- Anticipation effects test\n",
        "- Publication-ready figures\n",
        "- LaTeX tables\n",
        "\n",
        "---\n",
        "\n",
        "**References:**\n",
        "\n",
        "1. Gavrilova, E., Langørgen, A., & Zoutman, F. T. (2025). \"Difference-in-Difference Causal Forests With an Application to Payroll Tax Incidence in Norway.\" *Journal of Applied Econometrics*.\n",
        "\n",
        "2. Rambachan, A., & Roth, J. (2023). \"A More Credible Approach to Parallel Trends.\" *Review of Economic Studies*, 90(5), 2555-2591.\n",
        "\n",
        "3. Athey, S., & Imbens, G. W. (2022). \"Design-based analysis in difference-in-differences settings with staggered adoption.\" *Journal of Econometrics*, 226(1), 62-79."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
